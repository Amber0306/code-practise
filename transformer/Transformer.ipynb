{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n",
    "\n",
    "#### CNN\n",
    "+ 权重共享 平移不变性、可并行计算\n",
    "+ 滑动窗口 局部关联性建模、依靠多层堆积来进行长程建模\n",
    "+ 对相对位置敏感、对绝对位置不敏感\n",
    "\n",
    "#### RNN 依次有序递归建模\n",
    "+ 对顺序敏感\n",
    "+ 串行计算耗时\n",
    "+ 长程建模能力弱\n",
    "+ 计算复杂度与序列长度呈线性关系\n",
    "+ 单步计算复杂度不变\n",
    "+ 对相对位置敏感，对绝对位置敏感\n",
    "  \n",
    "#### tranformer\n",
    "+ 无局部假设\n",
    "  + 可并行计算\n",
    "  + 对相对位置不敏感\n",
    "+ 无有序假设\n",
    "  + 需要位置编码反映位置变化对特征的影响\n",
    "  + 对绝对位置不敏感\n",
    "+ 任意两字符都可以建模\n",
    "  + 擅长长短程建模\n",
    "  + 自注意力机制需要序列长度的平方级复杂运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer encoder\n",
    "+ input word embedding\n",
    "  由稀疏的one-hot进入一个不带bias的FFN得到一个稠密的连续箱梁\n",
    "+ position encoding\n",
    "  + 通过sin/cos来固定表征\n",
    "    + 每个位置确定\n",
    "    + 对于不同的句子，相同位置的距离一致\n",
    "    + 可以推广到更长的测试句子\n",
    "  + pe(pos+k)可以写成pe(k)的线性组合\n",
    "  + 通过残差连接来是的位置信息流入深层\n",
    "+ multi-head self-attention\n",
    "  + 建模能力更强，表征空间更丰富\n",
    "  + 由多组Q\\K\\V构成，每组单独计算一个attention向量\n",
    "  + 把每组的attention向量拼起来，并进入一个FFN中得到最终的向量\n",
    "+ feed-forward network\n",
    "  + 只考虑每个单独位置进行建模\n",
    "  + 不同位置参数共享\n",
    "  + 类似于1*1 pointwise convolution\n",
    "\n",
    "### Transformer Decoder\n",
    "+ output word embedding\n",
    "+ masked multi-head self-attention\n",
    "+ multi-head cross-attention\n",
    "+ feed-forward network\n",
    "+ softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自回归模型\n",
    "+ word embedding\n",
    "+ position embeding\n",
    "+ encoder self-attention mask\n",
    "+ intra-attention mask\n",
    "+ decoder self-attention mask\n",
    "+ multi-head self-attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. work embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 3])\n",
      "tensor([4, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# word embedding, 以序列建模为例\n",
    "# 考虑source sentence target sentence\n",
    "# 这里考虑离散的建模\n",
    "# 构建序列，序列字符以其在词表索引形式表示\n",
    "\n",
    "batch_size = 2\n",
    "src_len = torch.randint(2,5,(batch_size,))\n",
    "tgt_len = torch.randint(2,5,(batch_size,))\n",
    "# 生成两个序列，每个序列都有一个随机生成的长度，最小为2，最大为5\n",
    "# src_seq\n",
    "# tgt_seq\n",
    "print(src_len)\n",
    "print(tgt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([3, 2, 0, 0, 0]), tensor([2, 1, 3, 4, 0])]\n",
      "[tensor([2, 2, 5, 3, 0]), tensor([3, 7, 4, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "# 序列单词总数，单词表大小\n",
    "max_num_src_words = 8\n",
    "max_num_tgt_words = 8\n",
    "#  序列最大程度\n",
    "max_src_seq_len = 5\n",
    "max_tgt_seq_len = 5\n",
    "\n",
    "src_len = torch.Tensor([2,4]).to(torch.int32)\n",
    "tgt_len = torch.Tensor([4,3]).to(torch.int32)\n",
    "\n",
    "# 以单词索引构成的句子\n",
    "# src_seq = torch.cat([torch.unsequeeze(F.pad(torch.randint(1,max_num_src_words,(L,)),(0,max_src_seq_len-L)),0) \\ \n",
    "#                     for L in src_len ])\n",
    "src_seq = [ F.pad(torch.randint(1,max_num_src_words,(L,)),(0,max_src_seq_len-L)) for L in src_len ]\n",
    "\n",
    "print(src_seq)\n",
    "# 71 1364\n",
    "tgt_seq = [ F.pad(torch.randint(1,max_num_tgt_words,(L,)),(0,max_src_seq_len-L)) for L in tgt_len ]\n",
    "print(tgt_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 2, 0, 0, 0],\n",
      "        [2, 1, 3, 4, 0]])\n",
      "tensor([[2, 2, 5, 3, 0],\n",
      "        [3, 7, 4, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 对每个张量做pad,拼在一起\n",
    "# torch.unsequeeze升维度\n",
    "# src_seq = [torch.unsqueeze(T,dim=1) for T in src_seq]\n",
    "# print(src_seq)\n",
    "# torch.cat两个张量拼接，只能在已有的维度上，横向拼或者纵向拼\n",
    "# 默认值为0\n",
    "src_seq = torch.stack(tuple(src_seq),0)\n",
    "print(src_seq)\n",
    "tgt_seq = torch.stack(tuple(tgt_seq),0)\n",
    "print(tgt_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.6906,  1.2310,  0.3961, -0.5545],\n",
      "        [-0.2322,  1.2972,  0.3335, -0.2356],\n",
      "        [-0.9117, -0.0281,  0.7198,  0.0489],\n",
      "        [ 1.8042,  0.3087,  0.0875,  0.7060],\n",
      "        [ 0.2757, -0.8721, -0.2537, -0.2445],\n",
      "        [ 0.2626, -0.3904, -0.4275, -1.5268],\n",
      "        [-0.0972,  0.0288, -0.6968,  0.3374],\n",
      "        [-0.1964,  2.2362, -0.0749, -1.5696],\n",
      "        [-1.0461,  0.2858,  0.5081, -1.0913]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 构造embedding\n",
    "model_dim = 4\n",
    "\n",
    "src_embedding_table = nn.Embedding(max_num_src_words+1,model_dim)\n",
    "tgt_embedding_table = nn.Embedding(max_num_tgt_words+1,model_dim)\n",
    "print(src_embedding_table.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 2, 0, 0, 0],\n",
      "        [2, 1, 3, 4, 0]])\n",
      "tensor([[[ 1.8042,  0.3087,  0.0875,  0.7060],\n",
      "         [-0.9117, -0.0281,  0.7198,  0.0489],\n",
      "         [ 0.6906,  1.2310,  0.3961, -0.5545],\n",
      "         [ 0.6906,  1.2310,  0.3961, -0.5545],\n",
      "         [ 0.6906,  1.2310,  0.3961, -0.5545]],\n",
      "\n",
      "        [[-0.9117, -0.0281,  0.7198,  0.0489],\n",
      "         [-0.2322,  1.2972,  0.3335, -0.2356],\n",
      "         [ 1.8042,  0.3087,  0.0875,  0.7060],\n",
      "         [ 0.2757, -0.8721, -0.2537, -0.2445],\n",
      "         [ 0.6906,  1.2310,  0.3961, -0.5545]]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "src_embedding = src_embedding_table(src_seq)\n",
    "print(src_seq)\n",
    "print(src_embedding)\n",
    "# 迪奥用embedding的forward方法\n",
    "tgt_embedding = tgt_embedding_table(tgt_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. position embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "position embedding公式\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P E_{(p o s, 2 i)} &=\\sin \\left(p o s / 10000^{2 i / d_{\\mathrm{model}}}\\right) \\\\\n",
    "P E_{(\\text {pos }, 2 i+1)} &=\\cos \\left(p o s / 10000^{2 i / d_{\\mathrm{model}}}\\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "tensor([0.0000, 0.5000])\n",
      "tensor([[0.0000, 0.5000]])\n",
      "tensor([[  1., 100.]])\n"
     ]
    }
   ],
   "source": [
    "# 构造位置编码\n",
    "# sin/cos 泛化能力比较强，具有对称性和唯一性\n",
    "# \n",
    "max_position_len = 5\n",
    "\n",
    "# 奇数列用cos，偶数列用sin\n",
    "pos_mat = torch.arange(max_position_len)\n",
    "print(pos_mat)\n",
    "# pos决定行，i决定列\n",
    "pos_mat = pos_mat.reshape((-1,1))\n",
    "print(pos_mat)\n",
    "\n",
    "import numpy as np\n",
    "# 列矩阵\n",
    "i_mat = torch.Tensor(np.arange(0,model_dim,2))/model_dim\n",
    "print(i_mat)\n",
    "i_mat = i_mat.unsqueeze(0)\n",
    "print(i_mat)\n",
    "\n",
    "i_mat = torch.pow(10000, i_mat)\n",
    "print(i_mat)\n",
    "pos_mat = pos_mat.float()\n",
    "i_mat = i_mat.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.8415,  0.0000,  0.0100,  0.0000],\n",
      "        [ 0.9093,  0.0000,  0.0200,  0.0000],\n",
      "        [ 0.1411,  0.0000,  0.0300,  0.0000],\n",
      "        [-0.7568,  0.0000,  0.0400,  0.0000]])\n",
      "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
      "        [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
      "        [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
      "        [ 0.1411, -0.9900,  0.0300,  0.9996],\n",
      "        [-0.7568, -0.6536,  0.0400,  0.9992]])\n"
     ]
    }
   ],
   "source": [
    "pe_embedding_table = torch.zeros(max_position_len, model_dim).float()\n",
    "print(pe_embedding_table)\n",
    "pe_embedding_table[:,0::2] = torch.sin(pos_mat/i_mat)\n",
    "print(pe_embedding_table)\n",
    "pe_embedding_table[:,1::2] = torch.cos(pos_mat/i_mat)\n",
    "print(pe_embedding_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
      "        [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
      "        [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
      "        [ 0.1411, -0.9900,  0.0300,  0.9996],\n",
      "        [-0.7568, -0.6536,  0.0400,  0.9992]])\n",
      "[tensor([0, 1, 2, 3]), tensor([0, 1, 2, 3])]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-924982e6765b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msrc_pe_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpe_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# tgt_pe_embedding = pe_embedding(tgt_pos)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_pe_embedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MyApp\\MLearning\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MyApp\\MLearning\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m         return F.embedding(\n\u001b[0;32m    116\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\MyApp\\MLearning\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1504\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1505\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1506\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "pe_embedding = nn.Embedding(max_position_len,model_dim)\n",
    "pe_embedding.weight = nn.Parameter(pe_embedding_table,requires_grad=False)\n",
    "print(pe_embedding.weight)\n",
    "\n",
    "src_pos = [torch.arange(max(src_len)) for _ in src_len]\n",
    "print(src_pos)\n",
    "\n",
    "src_pe_embedding = pe_embedding(src_pos)\n",
    "# tgt_pe_embedding = pe_embedding(tgt_pos)\n",
    "print(src_pe_embedding)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36e5de9c574c9cc55882ba42368a9f17b8afe201f20396b27fba2b387c169958"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
