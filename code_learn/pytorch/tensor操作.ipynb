{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度裁剪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1037, 0.3527],\n",
      "        [0.8745, 0.7546]])\n",
      "tensor([[1.0374, 3.5275],\n",
      "        [8.7450, 7.5461]])\n",
      "tensor([[2.3869, 6.0793],\n",
      "        [1.6707, 8.2301]])\n"
     ]
    }
   ],
   "source": [
    "# torch.clamp(input, min, max, out=None) → Tensor：将输入input张量每个元素的夹紧到区间 [min,max]，并返回结果到一个新张量。\n",
    "a = torch.rand(2,2)\n",
    "print(a)\n",
    "a = a*10\n",
    "print(a)\n",
    "a = torch.rand(2,2)*10\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function clamp:\n",
      "\n",
      "clamp(...)\n",
      "    clamp(input, min, max, *, out=None) -> Tensor\n",
      "    \n",
      "    Clamp all elements in :attr:`input` into the range `[` :attr:`min`, :attr:`max` `]`.\n",
      "    Let min_value and max_value be :attr:`min` and :attr:`max`, respectively, this returns:\n",
      "    \n",
      "    .. math::\n",
      "        y_i = \\min(\\max(x_i, \\text{min\\_value}), \\text{max\\_value})\n",
      "    \n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor.\n",
      "        min (Number): lower-bound of the range to be clamped to\n",
      "        max (Number): upper-bound of the range to be clamped to\n",
      "    \n",
      "    Keyword args:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(4)\n",
      "        >>> a\n",
      "        tensor([-1.7120,  0.1734, -0.0478, -0.0922])\n",
      "        >>> torch.clamp(a, min=-0.5, max=0.5)\n",
      "        tensor([-0.5000,  0.1734, -0.0478, -0.0922])\n",
      "    \n",
      "    .. function:: clamp(input, *, min, out=None) -> Tensor\n",
      "    \n",
      "    Clamps all elements in :attr:`input` to be larger or equal :attr:`min`.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor.\n",
      "    \n",
      "    Keyword args:\n",
      "        min (Number): minimal value of each element in the output\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(4)\n",
      "        >>> a\n",
      "        tensor([-0.0299, -2.3184,  2.1593, -0.8883])\n",
      "        >>> torch.clamp(a, min=0.5)\n",
      "        tensor([ 0.5000,  0.5000,  2.1593,  0.5000])\n",
      "    \n",
      "    .. function:: clamp(input, *, max, out=None) -> Tensor\n",
      "    \n",
      "    Clamps all elements in :attr:`input` to be smaller or equal :attr:`max`.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor.\n",
      "    \n",
      "    Keyword args:\n",
      "        max (Number): maximal value of each element in the output\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(4)\n",
      "        >>> a\n",
      "        tensor([ 0.7753, -0.4702, -0.4599,  1.1899])\n",
      "        >>> torch.clamp(a, max=0.5)\n",
      "        tensor([ 0.5000, -0.4702, -0.4599,  0.5000])\n",
      "\n",
      "tensor([[2.3869, 6.0793],\n",
      "        [2.0000, 7.0000]])\n"
     ]
    }
   ],
   "source": [
    "help(torch.clamp)\n",
    "b = torch.clamp(a,2,7)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 索引与数据筛选"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   -  torch.where(codition,x,y):按照条件从x和y中选出满足条件的元素组成新的tensor，输入参数condition：条件限制，如果满足条件，则选择a，否则选择b作为输出\n",
    "   -  torch.gather(input,dim,index,out=None):在指定维度上按照索引赋值输出tensor\n",
    "   -  torch.index_select(input,dim,index,out=None):按照指定索引赋值输出tensor\n",
    "   -  torch.masked_select(input,mask,out=None):按照mask输出tensor，输出为向量\n",
    "   -  torch.take(input,indices):将输入看成1D-tensor，按照索引得到输出tensor\n",
    "   -  torch.nonzero(input,out=None):输出非0元素的坐标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2675, 0.5273, 0.1901, 0.9465],\n",
      "        [0.3886, 0.3042, 0.0509, 0.7136],\n",
      "        [0.3067, 0.8536, 0.4764, 0.8760],\n",
      "        [0.9923, 0.3294, 0.3638, 0.8732]])\n",
      "tensor([[0.5966, 0.9615, 0.0232, 0.8825],\n",
      "        [0.9075, 0.6064, 0.3109, 0.2927],\n",
      "        [0.1184, 0.9410, 0.7856, 0.1840],\n",
      "        [0.4286, 0.0283, 0.7988, 0.5401]])\n",
      "tensor([[0.5966, 0.5273, 0.0232, 0.9465],\n",
      "        [0.9075, 0.6064, 0.3109, 0.7136],\n",
      "        [0.1184, 0.8536, 0.7856, 0.8760],\n",
      "        [0.9923, 0.0283, 0.7988, 0.8732]])\n"
     ]
    }
   ],
   "source": [
    "# torch.where(codition,x,y)\n",
    "b = torch.rand(4,4)\n",
    "c = torch.rand(4,4)\n",
    "print(b)\n",
    "print(c)\n",
    "out = torch.where(b>0.5,b,c)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "        15., 16.])\n",
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.],\n",
      "        [13., 14., 15., 16.]])\n",
      "tensor([[ 1.,  6.,  7.,  8.],\n",
      "        [ 1.,  6., 11., 12.],\n",
      "        [ 1.,  6., 15., 16.]])\n",
      "torch.Size([3, 4])\n",
      "tensor([[ 1.,  2.,  2.,  2.],\n",
      "        [ 5.,  6.,  7.,  7.],\n",
      "        [ 9., 10., 12., 12.]])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# torch.gather(input,dim,index,out=None)\n",
    "e = torch.linspace(1,16,16)\n",
    "print(e)\n",
    "e = e.view(4,4)\n",
    "print(e)\n",
    "out = torch.gather(e,dim=0,index=torch.tensor([[0,1,1,1],[0,1,2,2],[0,1,3,3]]))\n",
    "print(out)\n",
    "print(out.shape)\n",
    "#dim=0, out[i, j, k] = input[index[i, j, k], j, k]\n",
    "#dim=1, out[i, j, k] = input[i, index[i, j, k], k]\n",
    "#dim=2, out[i, j, k] = input[i, j, index[i, j, k]]\n",
    "out = torch.gather(e,dim=1,index=torch.tensor([[0,1,1,1],[0,1,2,2],[0,1,3,3]]))\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function linspace:\n",
      "\n",
      "linspace(...)\n",
      "    linspace(start, end, steps, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "    \n",
      "    Creates a one-dimensional tensor of size :attr:`steps` whose values are evenly\n",
      "    spaced from :attr:`start` to :attr:`end`, inclusive. That is, the value are:\n",
      "    \n",
      "    .. math::\n",
      "        (\\text{start},\n",
      "        \\text{start} + \\frac{\\text{end} - \\text{start}}{\\text{steps} - 1},\n",
      "        \\ldots,\n",
      "        \\text{start} + (\\text{steps} - 2) * \\frac{\\text{end} - \\text{start}}{\\text{steps} - 1},\n",
      "        \\text{end})\n",
      "    \n",
      "    \n",
      "    .. warning::\n",
      "        Not providing a value for :attr:`steps` is deprecated. For backwards\n",
      "        compatibility, not providing a value for :attr:`steps` will create a tensor\n",
      "        with 100 elements. Note that this behavior is not reflected in the\n",
      "        documented function signature and should not be relied on. In a future\n",
      "        PyTorch release, failing to provide a value for :attr:`steps` will throw a\n",
      "        runtime error.\n",
      "    \n",
      "    Args:\n",
      "        start (float): the starting value for the set of points\n",
      "        end (float): the ending value for the set of points\n",
      "        steps (int): size of the constructed tensor\n",
      "    \n",
      "    Keyword arguments:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "            Default: ``torch.strided``.\n",
      "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "            Default: if ``None``, uses the current device for the default tensor type\n",
      "            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "        requires_grad (bool, optional): If autograd should record operations on the\n",
      "            returned tensor. Default: ``False``.\n",
      "    \n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.linspace(3, 10, steps=5)\n",
      "        tensor([  3.0000,   4.7500,   6.5000,   8.2500,  10.0000])\n",
      "        >>> torch.linspace(-10, 10, steps=5)\n",
      "        tensor([-10.,  -5.,   0.,   5.,  10.])\n",
      "        >>> torch.linspace(start=-10, end=10, steps=5)\n",
      "        tensor([-10.,  -5.,   0.,   5.,  10.])\n",
      "        >>> torch.linspace(start=-10, end=10, steps=1)\n",
      "        tensor([-10.])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.linspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7956, 0.9869, 0.5396, 0.1974],\n",
      "        [0.6822, 0.7947, 0.4258, 0.3967],\n",
      "        [0.6043, 0.5952, 0.3390, 0.4100],\n",
      "        [0.6336, 0.7922, 0.3681, 0.3948]])\n",
      "tensor([0, 3, 2])\n",
      "tensor([[0.7956, 0.9869, 0.5396, 0.1974],\n",
      "        [0.6336, 0.7922, 0.3681, 0.3948],\n",
      "        [0.6043, 0.5952, 0.3390, 0.4100]])\n",
      "torch.Size([3, 4])\n",
      "tensor([[0.7956, 0.1974],\n",
      "        [0.6336, 0.3948],\n",
      "        [0.6043, 0.4100]])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# torch.index_select(input,dim,index,out=None)\n",
    "d = torch.rand(4,4)\n",
    "print(d)\n",
    "index = torch.tensor([0,3,2])\n",
    "print(index)\n",
    "out = torch.index_select(d,dim=0,index=index)\n",
    "# 按列取不同行\n",
    "print(out)\n",
    "print(out.shape)\n",
    "out = torch.index_select(out,dim=1,index=torch.tensor([0,3]))\n",
    "# 按列取不同行\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.],\n",
      "        [13., 14., 15., 16.]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False,  True,  True,  True],\n",
      "        [ True,  True,  True,  True]])\n",
      "tensor([10., 11., 12., 13., 14., 15., 16.])\n"
     ]
    }
   ],
   "source": [
    "# torch.masked_select(input,mask,out=None)\n",
    "f = torch.linspace(1,16,16).view(4,4)\n",
    "mask = torch.gt(f,9)\n",
    "print(f)\n",
    "print(mask)\n",
    "out = torch.masked_select(f,mask)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.],\n",
      "        [13., 14., 15., 16.]])\n",
      "tensor([ 1., 16., 14., 11.])\n"
     ]
    }
   ],
   "source": [
    "# torch.take(input,indices)\n",
    "g = torch.linspace(1,16,16).view(4,4)\n",
    "print(g)\n",
    "h = torch.take(g,index = torch.tensor([0,15,13,10]))\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [0, 2],\n",
      "        [1, 0],\n",
      "        [1, 1],\n",
      "        [1, 3]])\n"
     ]
    }
   ],
   "source": [
    "# torch.nonzero(input,out=None)\n",
    "i = torch.tensor([[0,1,2,0],[2,3,0,1]])\n",
    "out = torch.nonzero(i)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 组合 拼接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.cat(seq,dim=0,out=None):按照已经存在的维度进行拼接\n",
    "- torch.stack(seq,dim=0,out=None):沿着一个新维度对输入张量序列进行连接。 序列中所有的张量都应该为相同形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor([[[ 1.,  7.],\n",
      "         [ 2.,  8.],\n",
      "         [ 3.,  9.]],\n",
      "\n",
      "        [[ 4., 10.],\n",
      "         [ 5., 11.],\n",
      "         [ 6., 12.]]])\n",
      "torch.Size([2, 3, 2])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor([[[ 1.,  2.,  3.],\n",
      "         [ 7.,  8.,  9.]],\n",
      "\n",
      "        [[ 4.,  5.,  6.],\n",
      "         [10., 11., 12.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.]],\n",
      "\n",
      "        [[ 7.,  8.,  9.],\n",
      "         [10., 11., 12.]]])\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "j = torch.linspace(1,6,6).view(2,3)\n",
    "k = torch.linspace(7,12,6).view(2,3)\n",
    "print(j)\n",
    "print(k)\n",
    "out = torch.stack((j,k),dim=2)\n",
    "print(out)\n",
    "print(out.shape)\n",
    "print(out[:,:,0])\n",
    "print(out[:,:,1])\n",
    "\n",
    "out = torch.stack((j,k),dim=1)\n",
    "print(out)\n",
    "print(out.shape)\n",
    "\n",
    "out = torch.stack((j,k),dim=0)\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor([[ 1.,  2.,  3.,  7.,  8.,  9.],\n",
      "        [ 4.,  5.,  6., 10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "out = torch.cat((j,k),dim=0)\n",
    "print(out)\n",
    "out = torch.cat((j,k),dim=1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.3300, 3.3300, 3.3300],\n",
      "        [3.3300, 3.3300, 3.3300]])\n"
     ]
    }
   ],
   "source": [
    "l = torch.full((2,3),3.33)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 切片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.chunk(tensor,chunks,dim=0):按照某个维度平均分块（最后一个可能小于平均值）\n",
    "- torch.split(tensor,split_size_or_sections,dim=0):按照某个维度依照第二个参数给出的list或者int进行分割tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.]])\n",
      "(tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8.]]), tensor([[ 9., 10., 11., 12.]]))\n",
      "(tensor([[ 1.,  2.],\n",
      "        [ 5.,  6.],\n",
      "        [ 9., 10.]]), tensor([[ 3.,  4.],\n",
      "        [ 7.,  8.],\n",
      "        [11., 12.]]))\n"
     ]
    }
   ],
   "source": [
    "m = torch.linspace(1,12,12).view(3,4)\n",
    "print(m)\n",
    "out = torch.chunk(m,2,dim=0)\n",
    "print(out)\n",
    "out = torch.chunk(m,2,dim=1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.]])\n",
      "(tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8.]]), tensor([[ 9., 10., 11., 12.]]))\n",
      "(tensor([[ 1.,  2.],\n",
      "        [ 5.,  6.],\n",
      "        [ 9., 10.]]), tensor([[ 3.,  4.],\n",
      "        [ 7.,  8.],\n",
      "        [11., 12.]]))\n",
      "(tensor([[1., 2., 3., 4.]]), tensor([[ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.]]))\n",
      "(tensor([[1.],\n",
      "        [5.],\n",
      "        [9.]]), tensor([[ 2.,  3.],\n",
      "        [ 6.,  7.],\n",
      "        [10., 11.]]), tensor([[ 4.],\n",
      "        [ 8.],\n",
      "        [12.]]))\n"
     ]
    }
   ],
   "source": [
    "n = torch.linspace(1,12,12).view(3,4)\n",
    "print(n)\n",
    "out = torch.split(n,2,dim=0)\n",
    "print(out)\n",
    "out = torch.split(n,2,dim=1)\n",
    "print(out)\n",
    "\n",
    "out = torch.split(n,[1,2],dim=0)\n",
    "print(out)\n",
    "out = torch.split(n,[1,2,1],dim=1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 变形"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  torch.reshape(input,shape)\n",
    "-  torch.t(input):只针对2D tensor转置\n",
    "-  torch.transpose(input,dim0,dim1):交换两个维度\n",
    "-  torch.squeeze(input,dim=None,out=None):去除那些维度大小为1的维度\n",
    "-  torch.unbind(tensor,dim=0):去除某个维度\n",
    "-  torch.unsqueeze(input,dim,out=None):在指定位置添加维度,dim=-1在最后添加\n",
    "-  torch.flip(input,dims):按照给定维度翻转张量\n",
    "-  torch.rot90(input,k,dims):按照指定维度和旋转次数进行张量旋转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4176, 0.2336, 0.2591],\n",
      "        [0.3411, 0.8867, 0.4005]])\n",
      "tensor([[0.4176, 0.2336],\n",
      "        [0.2591, 0.3411],\n",
      "        [0.8867, 0.4005]])\n"
     ]
    }
   ],
   "source": [
    "o = torch.rand(2,3)\n",
    "print(o)\n",
    "out = torch.reshape(o,(3,2))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "p = torch.linspace(1,6,6).view(2,3)\n",
    "print(p)\n",
    "out = torch.t(p)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9888, 0.0155, 0.0528, 0.7863],\n",
      "         [0.8869, 0.6600, 0.4699, 0.8965],\n",
      "         [0.8320, 0.6582, 0.0845, 0.4513]],\n",
      "\n",
      "        [[0.3956, 0.9352, 0.3403, 0.2406],\n",
      "         [0.3031, 0.1658, 0.1991, 0.8396],\n",
      "         [0.7089, 0.6804, 0.3560, 0.9971]]])\n",
      "tensor([[[0.9888, 0.8869, 0.8320],\n",
      "         [0.0155, 0.6600, 0.6582],\n",
      "         [0.0528, 0.4699, 0.0845],\n",
      "         [0.7863, 0.8965, 0.4513]],\n",
      "\n",
      "        [[0.3956, 0.3031, 0.7089],\n",
      "         [0.9352, 0.1658, 0.6804],\n",
      "         [0.3403, 0.1991, 0.3560],\n",
      "         [0.2406, 0.8396, 0.9971]]])\n",
      "tensor([[[0.9888, 0.0155, 0.0528, 0.7863],\n",
      "         [0.3956, 0.9352, 0.3403, 0.2406]],\n",
      "\n",
      "        [[0.8869, 0.6600, 0.4699, 0.8965],\n",
      "         [0.3031, 0.1658, 0.1991, 0.8396]],\n",
      "\n",
      "        [[0.8320, 0.6582, 0.0845, 0.4513],\n",
      "         [0.7089, 0.6804, 0.3560, 0.9971]]])\n"
     ]
    }
   ],
   "source": [
    "q = torch.rand(2,3,4)\n",
    "print(q)\n",
    "out = torch.transpose(q,1,2)\n",
    "print(out)\n",
    "out = torch.transpose(q,0,1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5352, 0.9923, 0.3547]],\n",
      "\n",
      "        [[0.7620, 0.1928, 0.9086]]])\n",
      "torch.Size([2, 1, 3])\n",
      "tensor([[0.5352, 0.9923, 0.3547],\n",
      "        [0.7620, 0.1928, 0.9086]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "r = torch.rand(2,1,3)\n",
    "print(r)\n",
    "print(r.shape)\n",
    "out = torch.squeeze(r)\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1767, 0.5190, 0.3751],\n",
      "         [0.5347, 0.1648, 0.8326]],\n",
      "\n",
      "        [[0.2329, 0.1216, 0.0524],\n",
      "         [0.0655, 0.3150, 0.6624]]])\n",
      "torch.Size([2, 2, 3])\n",
      "(tensor([[0.1767, 0.5190, 0.3751],\n",
      "        [0.5347, 0.1648, 0.8326]]), tensor([[0.2329, 0.1216, 0.0524],\n",
      "        [0.0655, 0.3150, 0.6624]]))\n",
      "(tensor([[0.1767, 0.5190, 0.3751],\n",
      "        [0.2329, 0.1216, 0.0524]]), tensor([[0.5347, 0.1648, 0.8326],\n",
      "        [0.0655, 0.3150, 0.6624]]))\n",
      "(tensor([[0.1767, 0.5347],\n",
      "        [0.2329, 0.0655]]), tensor([[0.5190, 0.1648],\n",
      "        [0.1216, 0.3150]]), tensor([[0.3751, 0.8326],\n",
      "        [0.0524, 0.6624]]))\n"
     ]
    }
   ],
   "source": [
    "s = torch.rand(2,2,3)\n",
    "print(s)\n",
    "print(s.shape)\n",
    "out = torch.unbind(s,dim=0)\n",
    "# print(out.shape)\n",
    "print(out)\n",
    "out = torch.unbind(s,dim=1)\n",
    "# print(out.shape)\n",
    "print(out)\n",
    "out = torch.unbind(s,dim=2)\n",
    "# print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[0.7018, 0.2643, 0.4915],\n",
      "        [0.2416, 0.8697, 0.4686]])\n",
      "torch.Size([2, 3, 1])\n",
      "tensor([[[0.7018],\n",
      "         [0.2643],\n",
      "         [0.4915]],\n",
      "\n",
      "        [[0.2416],\n",
      "         [0.8697],\n",
      "         [0.4686]]])\n",
      "torch.Size([1, 2, 3])\n",
      "tensor([[[0.7018, 0.2643, 0.4915],\n",
      "         [0.2416, 0.8697, 0.4686]]])\n",
      "torch.Size([2, 1, 3])\n",
      "tensor([[[0.7018, 0.2643, 0.4915]],\n",
      "\n",
      "        [[0.2416, 0.8697, 0.4686]]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(2,3)\n",
    "print(t.shape)\n",
    "print(t)\n",
    "out = torch.unsqueeze(t,dim=-1)\n",
    "print(out.shape)\n",
    "print(out)\n",
    "out = torch.unsqueeze(t,dim=0)\n",
    "print(out.shape)\n",
    "print(out)\n",
    "out = torch.unsqueeze(t,dim=1)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[0.9165, 0.4422, 0.3880],\n",
      "        [0.4938, 0.5609, 0.2313]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0.2313, 0.5609, 0.4938],\n",
      "        [0.3880, 0.4422, 0.9165]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0.2313, 0.5609, 0.4938],\n",
      "        [0.3880, 0.4422, 0.9165]])\n",
      "torch.Size([3, 2])\n",
      "tensor([[0.4938, 0.9165],\n",
      "        [0.5609, 0.4422],\n",
      "        [0.2313, 0.3880]])\n"
     ]
    }
   ],
   "source": [
    "u = torch.rand(2,3)\n",
    "print(u.shape)\n",
    "print(u)\n",
    "out = torch.flip(u,dims=[0,1])\n",
    "print(out.shape)\n",
    "print(out)\n",
    "out = torch.flip(u,dims=[1,0])\n",
    "print(out.shape)\n",
    "print(out)\n",
    "\n",
    "# 维度和旋转次数\n",
    "out = torch.rot90(u, -1, dims=[0, 1]) #顺时针旋转90°  \n",
    "print(out.shape)\n",
    "print(out)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10e2f66ad254a986d59b2a855612166bbe41e1c910d0c6f6fbe42ff0ae514b74"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('pytorch-cpu-38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
