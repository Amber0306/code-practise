{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n",
    "\n",
    "#### CNN\n",
    "+ 权重共享 平移不变性、可并行计算\n",
    "+ 滑动窗口 局部关联性建模、依靠多层堆积来进行长程建模\n",
    "+ 对相对位置敏感、对绝对位置不敏感\n",
    "\n",
    "#### RNN 依次有序递归建模\n",
    "+ 对顺序敏感\n",
    "+ 串行计算耗时\n",
    "+ 长程建模能力弱\n",
    "+ 计算复杂度与序列长度呈线性关系\n",
    "+ 单步计算复杂度不变\n",
    "+ 对相对位置敏感，对绝对位置敏感\n",
    "  \n",
    "#### tranformer\n",
    "+ 无局部假设\n",
    "  + 可并行计算\n",
    "  + 对相对位置不敏感\n",
    "+ 无有序假设\n",
    "  + 需要位置编码反映位置变化对特征的影响\n",
    "  + 对绝对位置不敏感\n",
    "+ 任意两字符都可以建模\n",
    "  + 擅长长短程建模\n",
    "  + 自注意力机制需要序列长度的平方级复杂运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer encoder\n",
    "+ input word embedding\n",
    "  由稀疏的one-hot进入一个不带bias的FFN得到一个稠密的连续箱梁\n",
    "+ position encoding\n",
    "  + 通过sin/cos来固定表征\n",
    "    + 每个位置确定\n",
    "    + 对于不同的句子，相同位置的距离一致\n",
    "    + 可以推广到更长的测试句子\n",
    "  + pe(pos+k)可以写成pe(k)的线性组合\n",
    "  + 通过残差连接来是的位置信息流入深层\n",
    "+ multi-head self-attention\n",
    "  + 建模能力更强，表征空间更丰富\n",
    "  + 由多组Q\\K\\V构成，每组单独计算一个attention向量\n",
    "  + 把每组的attention向量拼起来，并进入一个FFN中得到最终的向量\n",
    "+ feed-forward network\n",
    "  + 只考虑每个单独位置进行建模\n",
    "  + 不同位置参数共享\n",
    "  + 类似于1*1 pointwise convolution\n",
    "\n",
    "### Transformer Decoder\n",
    "+ output word embedding\n",
    "+ masked multi-head self-attention\n",
    "+ multi-head cross-attention\n",
    "+ feed-forward network\n",
    "+ softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自回归模型\n",
    "+ word embedding\n",
    "+ position embeding\n",
    "+ encoder self-attention mask\n",
    "+ intra-attention mask\n",
    "+ decoder self-attention mask\n",
    "+ multi-head self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 4])\n",
      "tensor([4, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# word embedding, 以序列建模为例\n",
    "# 考虑source sentence target sentence\n",
    "# 这里考虑离散的建模\n",
    "# 构建序列，序列字符以其在词表索引形式表示\n",
    "\n",
    "batch_size = 2\n",
    "src_len = torch.randint(2,5,(batch_size,))\n",
    "tgt_len = torch.randint(2,5,(batch_size,))\n",
    "# 生成两个序列，每个序列都有一个随机生成的长度，最小为2，最大为5\n",
    "# src_seq\n",
    "# tgt_seq\n",
    "print(src_len)\n",
    "print(tgt_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([4, 2, 0, 0, 0]), tensor([2, 7, 5, 4, 0])]\n",
      "[tensor([1, 1, 5, 6, 0]), tensor([6, 1, 7, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "# 序列单词总数，单词表大小\n",
    "max_num_src_words = 8\n",
    "max_num_tgt_words = 8\n",
    "#  序列最大程度\n",
    "max_src_seq_len = 5\n",
    "max_tgt_seq_len = 5\n",
    "\n",
    "src_len = torch.Tensor([2,4]).to(torch.int32)\n",
    "tgt_len = torch.Tensor([4,3]).to(torch.int32)\n",
    "\n",
    "# 以单词索引构成的句子\n",
    "# src_seq = torch.cat([torch.unsequeeze(F.pad(torch.randint(1,max_num_src_words,(L,)),(0,max_src_seq_len-L)),0) \\ \n",
    "#                     for L in src_len ])\n",
    "src_seq = [ F.pad(torch.randint(1,max_num_src_words,(L,)),(0,max_src_seq_len-L)) for L in src_len ]\n",
    "\n",
    "print(src_seq)\n",
    "# 71 1364\n",
    "tgt_seq = [ F.pad(torch.randint(1,max_num_tgt_words,(L,)),(0,max_src_seq_len-L)) for L in tgt_len ]\n",
    "print(tgt_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 2, 0, 0, 0],\n",
      "        [2, 7, 5, 4, 0]])\n",
      "tensor([[1, 1, 5, 6, 0],\n",
      "        [6, 1, 7, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 对每个张量做pad,拼在一起\n",
    "# torch.unsequeeze升维度\n",
    "# src_seq = [torch.unsqueeze(T,dim=1) for T in src_seq]\n",
    "# print(src_seq)\n",
    "# torch.cat两个张量拼接，只能在已有的维度上，横向拼或者纵向拼\n",
    "# 默认值为0\n",
    "src_seq = torch.stack(tuple(src_seq),0)\n",
    "print(src_seq)\n",
    "tgt_seq = torch.stack(tuple(tgt_seq),0)\n",
    "print(tgt_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 7.2626e-04, -7.0833e-02, -9.3470e-01,  1.1986e+00],\n",
      "        [-6.2423e-01, -1.4757e+00, -1.5339e-01,  5.2330e-01],\n",
      "        [ 1.5762e-01,  1.0453e+00,  3.5325e-01, -8.5912e-01],\n",
      "        [-6.6104e-01, -6.0316e-02, -1.2233e+00, -1.7766e+00],\n",
      "        [ 2.0727e+00, -7.1832e-03, -4.9131e-01,  5.9102e-01],\n",
      "        [-7.9353e-01,  1.2585e+00, -1.7252e+00,  1.3896e+00],\n",
      "        [ 2.9879e-01, -1.4153e+00, -3.6494e-01,  5.6291e-01],\n",
      "        [ 3.0750e-01,  7.2336e-02, -9.4862e-01, -7.6832e-01],\n",
      "        [-6.4298e-01, -5.1511e-03,  8.5293e-01, -2.9075e-01]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 构造embedding\n",
    "model_dim = 4\n",
    "\n",
    "src_embedding_table = nn.Embedding(max_num_src_words+1,model_dim)\n",
    "tgt_embedding_table = nn.Embedding(max_num_tgt_words+1,model_dim)\n",
    "print(src_embedding_table.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 2, 0, 0, 0],\n",
      "        [2, 7, 5, 4, 0]])\n",
      "tensor([[[ 2.0727e+00, -7.1832e-03, -4.9131e-01,  5.9102e-01],\n",
      "         [ 1.5762e-01,  1.0453e+00,  3.5325e-01, -8.5912e-01],\n",
      "         [ 7.2626e-04, -7.0833e-02, -9.3470e-01,  1.1986e+00],\n",
      "         [ 7.2626e-04, -7.0833e-02, -9.3470e-01,  1.1986e+00],\n",
      "         [ 7.2626e-04, -7.0833e-02, -9.3470e-01,  1.1986e+00]],\n",
      "\n",
      "        [[ 1.5762e-01,  1.0453e+00,  3.5325e-01, -8.5912e-01],\n",
      "         [ 3.0750e-01,  7.2336e-02, -9.4862e-01, -7.6832e-01],\n",
      "         [-7.9353e-01,  1.2585e+00, -1.7252e+00,  1.3896e+00],\n",
      "         [ 2.0727e+00, -7.1832e-03, -4.9131e-01,  5.9102e-01],\n",
      "         [ 7.2626e-04, -7.0833e-02, -9.3470e-01,  1.1986e+00]]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "src_embedding = src_embedding_table(src_seq)\n",
    "print(src_seq)\n",
    "print(src_embedding)\n",
    "# 迪奥用embedding的forward方法\n",
    "tgt_embedding = tgt_embedding_table(tgt_seq)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36e5de9c574c9cc55882ba42368a9f17b8afe201f20396b27fba2b387c169958"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
